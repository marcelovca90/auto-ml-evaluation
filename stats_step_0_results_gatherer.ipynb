{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a148ba-71ea-436d-8896-a4f211d909fa",
   "metadata": {},
   "source": [
    "# Step 0: Results Gatherer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1028786b-d2f5-4c77-9e88-f3764547a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aaeffe6-6a16-4821-a1ab-a00314f4458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04067b28-e7b2-4b76-bbc4-728d1080672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'f1_score_weighted'\n",
    "\n",
    "datasets = {\n",
    "    'binary': [31, 37, 44, 1462, 1479, 1510, 40945],\n",
    "    'multiclass': [23, 36, 54, 181, 1466, 40691, 40975],\n",
    "    'multilabel_native': [285, 41464, 41465, 41468, 41470, 41471, 41473],\n",
    "    'multilabel_powerset': ['285ps', '41464ps', '41465ps', '41468ps', '41470ps', '41471ps', '41473ps']\n",
    "}\n",
    "\n",
    "frameworks = [\n",
    "    '4intelligence', 'autogluon', 'autokeras', 'autopytorch', 'autosklearn', 'evalml', 'fedot',\n",
    "    'flaml', 'gama', 'h2o', 'lightautoml', 'lightwood', 'mljar', 'naive', 'pycaret', 'tpot',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8ad0ec-d36c-477b-8cb0-8383369c78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def clean_and_save_results(results_list, scenario, output_dir=\"stats\"):\n",
    "    \"\"\"\n",
    "    Cleans the experimental results by:\n",
    "    1. Removing frameworks that failed across all datasets (all NaN in F1 Score & Training Time).\n",
    "    2. Removing rows where F1 Score < 0 or Training Time < 0.\n",
    "\n",
    "    Parameters:\n",
    "    - results_list (list of dict): List of trial results.\n",
    "    - scenario (str): The name of the scenario (used for file naming).\n",
    "    - output_dir (str): The directory where results will be saved (default: 'stats').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The cleaned DataFrame with invalid frameworks and trial results removed.\n",
    "    \"\"\"\n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame(results_list)\n",
    "    df[\"Trial\"] = df[\"Trial\"].astype('Int64')\n",
    "\n",
    "    # Remove frameworks that failed across ALL datasets\n",
    "    failed_frameworks = df.groupby(\"Framework\")[[\"F1 Score\", \"Training Time\"]].apply(lambda x: x.isna().all().all())\n",
    "    failed_frameworks = failed_frameworks[failed_frameworks].index.tolist()  # Get list of failed frameworks\n",
    "    df = df[~df[\"Framework\"].isin(failed_frameworks)]  # Drop those frameworks\n",
    "\n",
    "    # Remove rows where F1 Score < 0 or Training Time < 0\n",
    "    df = df[(df[\"F1 Score\"] >= 0) & (df[\"Training Time\"] >= 0)]\n",
    "\n",
    "    # Save to CSV\n",
    "    filename = f\"{output_dir}/{scenario}/{scenario}_experimental_results.csv\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    return df  # Return cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1a6b52-97de-47a6-b422-1c3ec4e4251a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Dataset Type</th>\n",
       "      <th>Framework</th>\n",
       "      <th>Trial</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>binary</td>\n",
       "      <td>4intelligence</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>174.789680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>binary</td>\n",
       "      <td>4intelligence</td>\n",
       "      <td>2</td>\n",
       "      <td>0.602864</td>\n",
       "      <td>171.077410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>binary</td>\n",
       "      <td>4intelligence</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600504</td>\n",
       "      <td>121.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>binary</td>\n",
       "      <td>4intelligence</td>\n",
       "      <td>4</td>\n",
       "      <td>0.600504</td>\n",
       "      <td>158.295441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>binary</td>\n",
       "      <td>4intelligence</td>\n",
       "      <td>5</td>\n",
       "      <td>0.599930</td>\n",
       "      <td>168.605997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>41473ps</td>\n",
       "      <td>multilabel_powerset</td>\n",
       "      <td>tpot</td>\n",
       "      <td>16</td>\n",
       "      <td>0.193780</td>\n",
       "      <td>545.683002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>41473ps</td>\n",
       "      <td>multilabel_powerset</td>\n",
       "      <td>tpot</td>\n",
       "      <td>17</td>\n",
       "      <td>0.196621</td>\n",
       "      <td>550.792275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>41473ps</td>\n",
       "      <td>multilabel_powerset</td>\n",
       "      <td>tpot</td>\n",
       "      <td>18</td>\n",
       "      <td>0.149474</td>\n",
       "      <td>351.656300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>41473ps</td>\n",
       "      <td>multilabel_powerset</td>\n",
       "      <td>tpot</td>\n",
       "      <td>19</td>\n",
       "      <td>0.170534</td>\n",
       "      <td>581.061009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>41473ps</td>\n",
       "      <td>multilabel_powerset</td>\n",
       "      <td>tpot</td>\n",
       "      <td>20</td>\n",
       "      <td>0.190648</td>\n",
       "      <td>318.022755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset         Dataset Type      Framework  Trial  F1 Score  \\\n",
       "0          31               binary  4intelligence      1  0.598200   \n",
       "1          31               binary  4intelligence      2  0.602864   \n",
       "2          31               binary  4intelligence      3  0.600504   \n",
       "3          31               binary  4intelligence      4  0.600504   \n",
       "4          31               binary  4intelligence      5  0.599930   \n",
       "...       ...                  ...            ...    ...       ...   \n",
       "6426  41473ps  multilabel_powerset           tpot     16  0.193780   \n",
       "6427  41473ps  multilabel_powerset           tpot     17  0.196621   \n",
       "6428  41473ps  multilabel_powerset           tpot     18  0.149474   \n",
       "6429  41473ps  multilabel_powerset           tpot     19  0.170534   \n",
       "6430  41473ps  multilabel_powerset           tpot     20  0.190648   \n",
       "\n",
       "      Training Time  \n",
       "0        174.789680  \n",
       "1        171.077410  \n",
       "2        121.127800  \n",
       "3        158.295441  \n",
       "4        168.605997  \n",
       "...             ...  \n",
       "6426     545.683002  \n",
       "6427     550.792275  \n",
       "6428     351.656300  \n",
       "6429     581.061009  \n",
       "6430     318.022755  \n",
       "\n",
       "[6192 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_list = [] # Results for all scenarios\n",
    "\n",
    "for scenario, dataset_ids in datasets.items():\n",
    "    \n",
    "    this_results_list = []  # Results for this scenario\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "\n",
    "        for framework in frameworks:\n",
    "    \n",
    "            try:\n",
    "                with open(f'results/{scenario}/{dataset_id}/automl_{framework}.json', 'r') as fp:\n",
    "                    content = json.load(fp)\n",
    "                    f1_scores = [x['f1_score_weighted'] for x in content['results']]  # Extract scores\n",
    "                    training_times = [x['training_time'] for x in content['results']]  # Extract scores\n",
    "\n",
    "                    # Store each trial\n",
    "                    for trial_idx, (score, time) in enumerate(zip(f1_scores, training_times)):\n",
    "                        trial_result = {\n",
    "                            \"Dataset\": dataset_id,\n",
    "                            \"Dataset Type\": scenario,\n",
    "                            \"Framework\": framework,\n",
    "                            \"Trial\": trial_idx + 1,  # Make trials 1-based for readability\n",
    "                            \"F1 Score\": score,\n",
    "                            \"Training Time\": time\n",
    "                        }\n",
    "                        this_results_list.append(trial_result)\n",
    "                        all_results_list.append(trial_result)\n",
    "    \n",
    "            except Exception as e:\n",
    "                # Missing file or error → No results for this framework/dataset\n",
    "                trial_result_error = {\n",
    "                    \"Dataset\": dataset_id,\n",
    "                    \"Dataset Type\": scenario,\n",
    "                    \"Framework\": framework,\n",
    "                    \"Trial\": None,\n",
    "                    \"F1 Score\": None,\n",
    "                    \"Training Time\": None\n",
    "                }\n",
    "                this_results_list.append(trial_result_error)\n",
    "                all_results_list.append(trial_result_error)\n",
    "\n",
    "    this_df = clean_and_save_results(this_results_list, scenario)\n",
    "\n",
    "\n",
    "all_df = clean_and_save_results(all_results_list, \"all\")\n",
    "\n",
    "# Show DataFrame\n",
    "all_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
